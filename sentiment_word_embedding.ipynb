{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_word_embedding.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/georgeliu1998/sentiment_word_embedding/blob/master/sentiment_word_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "M30eGYwFZTaE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis with Word Embedding and RNN"
      ]
    },
    {
      "metadata": {
        "id": "lhRK0W7VZL8D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setting up the Environment"
      ]
    },
    {
      "metadata": {
        "id": "0fnH-78sMTIj",
        "colab_type": "code",
        "outputId": "ed13bf29-5335-4dda-9c0f-68c032ff1be6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from numpy.random import seed\n",
        "seed(8)\n",
        "\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(8)\n",
        "\n",
        "import numpy as np\n",
        "seed = np.random.RandomState(8)\n",
        "\n",
        "import urllib.request\n",
        "import tarfile\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "from time import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "d6_GZp-uB6Pg",
        "colab_type": "code",
        "outputId": "78b21d04-4d5f-437e-a2a8-8b7373329494",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "id": "TebrmRNH7yX_",
        "colab_type": "code",
        "outputId": "a8035982-f38b-4aa3-f923-b63811218219",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_md==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.0.0/en_core_web_md-2.0.0.tar.gz#egg=en_core_web_md==2.0.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.0.0/en_core_web_md-2.0.0.tar.gz (120.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 120.9MB 56.7MB/s \n",
            "\u001b[?25hInstalling collected packages: en-core-web-md\n",
            "  Running setup.py install for en-core-web-md ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n",
            "\u001b[?25hSuccessfully installed en-core-web-md-2.0.0\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/en_core_web_md -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/en_core_web_md\n",
            "\n",
            "    You can now load the model via spacy.load('en_core_web_md')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JYC2cCNcik-Q",
        "colab_type": "code",
        "outputId": "dc697da2-8879-40bb-8705-c561aeefe646",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2wNUgX54YRs5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Getting the Data"
      ]
    },
    {
      "metadata": {
        "id": "xJJvv-Xaoc0n",
        "colab_type": "code",
        "outputId": "94b731c8-b950-431b-c917-8c2d043427d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "url = 'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
        "\n",
        "path = './gdrive/My Drive/WorkingDir/sentiment_word_embedding'\n",
        "download_folder = 'raw_data'\n",
        "download_name = 'imdb.tar.gz'\n",
        "path_name = os.path.join(path, download_folder, download_name)\n",
        "\n",
        "# Download data to the specified path\n",
        "urllib.request.urlretrieve(url, path_name)\n",
        "\n",
        "#extract_path = os.path.join(path, download_folder)\n",
        "\n",
        "with tarfile.open(path_name) as tar:\n",
        "  #tar.extractall(path=extract_path)\n",
        "  tar.extractall()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./gdrive/My Drive/WorkingDir/sentiment_word_embedding/raw_data/imdb.tar.gz',\n",
              " <http.client.HTTPMessage at 0x7fa4dbb55898>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "ci38QxEB_K7x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_imdb(path):\n",
        "  \"\"\"\n",
        "  Loads train and test data into dataframes.\n",
        "\n",
        "  Params\n",
        "  ---------------------\n",
        "  path: str\n",
        "    The path to the unzipped aclImdb folder.\n",
        "\n",
        "  Returns\n",
        "  ---------------------\n",
        "  df_train, df_test: tuple of of pandas df\n",
        "    The dataframes created from data\n",
        "  \"\"\"\n",
        "\n",
        "  data = {}\n",
        "\n",
        "  for split in ['train', 'test']:\n",
        "    data[split] = []\n",
        "\n",
        "    for label in ['pos', 'neg']:\n",
        "      sentiment = 1 if label == 'pos' else 0\n",
        "      file_names = os.listdir(os.path.join(path, split, label))\n",
        "\n",
        "      for file_name in file_names:\n",
        "        file_path = os.path.join(path, split, label, file_name)\n",
        "        with open(file_path, \"r\") as f:\n",
        "          review = f.read()\n",
        "\n",
        "          data[split].append([review, sentiment])\n",
        "\n",
        "  np.random.shuffle(data['train'])        \n",
        "  df_train = pd.DataFrame(data['train'], columns=['review', 'sentiment'])\n",
        "\n",
        "  np.random.shuffle(data['test'])\n",
        "  df_test = pd.DataFrame(data['test'], columns=['review', 'sentiment'])\n",
        "\n",
        "  return df_train, df_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s85H2xtP_Rge",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_train, df_test = load_imdb('./aclImdb')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "01VwUGX5p4fo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_df(df, path, save_name):\n",
        "  file_name = save_name + '.csv'\n",
        "  path_name = os.path.join(path, file_name)\n",
        "  \n",
        "  df.to_csv(path_name, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0EERavHavVyl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "save_df(df=df_train, path=path, save_name='df_train')\n",
        "save_df(df=df_test, path=path, save_name='df_test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c_dFI3BIrAfA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path = './gdrive/My Drive/WorkingDir/sentiment_word_embedding'\n",
        "\n",
        "df_train = pd.read_csv(os.path.join(path, 'df_train.csv'))\n",
        "df_test = pd.read_csv(os.path.join(path, 'df_test.csv'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g5niInBOaR_r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "  \"\"\"\n",
        "  Loads all train test data\n",
        "  \"\"\"\n",
        "  \n",
        "  path = './gdrive/My Drive/WorkingDir/sentiment_word_embedding'\n",
        "  \n",
        "  df_train = pd.read_csv(os.path.join(path, 'df_train.csv'))\n",
        "  df_test = pd.read_csv(os.path.join(path, 'df_test.csv'))\n",
        "  \n",
        "  X_train = np.loadtxt(os.path.join(path, 'X_train.csv'), delimiter=\",\")\n",
        "  X_test = np.loadtxt(os.path.join(path, 'X_test.csv'), delimiter=\",\")\n",
        "  y_train = df_train['sentiment'].values\n",
        "  y_test = df_test['sentiment'].values\n",
        "  \n",
        "  return X_train, X_test, y_train, y_test "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "grJH6_8ZYu8a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "X5zWJ-deU7ps",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess_text(text, lemmatizing=False):\n",
        "    \"\"\"\n",
        "    Preprocesses text by removing all stop words and lemmatizing.\n",
        "    \n",
        "    Params\n",
        "    --------------\n",
        "    text: str\n",
        "      the string to be cleaned\n",
        "    \n",
        "    Returns\n",
        "    --------------\n",
        "    text: str\n",
        "      the cleaned string\n",
        "\n",
        "    \"\"\"\n",
        "    text = text.lower()\n",
        "    \n",
        "    if lemmatizing:\n",
        "      lemmatizer = WordNetLemmatizer()\n",
        "      text = ' '.join([lemmatizer.lemmatize(word, pos='v') for word in text.split()])\n",
        "    \n",
        "    # Remove html tags\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    \n",
        "    # Replace punctuation with spaces\n",
        "    translator = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
        "    text = text.translate(translator)\n",
        "\n",
        "    # Remove stop words\n",
        "    text = ' '.join([word for word in text.split() if word not in stopwords.words('english')])\n",
        "    \n",
        "    # Remove additional white spaces\n",
        "    text = ' '.join(text.split())\n",
        "    \n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ok0pLI_fPqDY",
        "colab_type": "code",
        "outputId": "3ac534af-f104-4ce2-a7c0-17e3441d83e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "t1 = time()\n",
        "\n",
        "X_train = df_train['review'].apply(preprocess_text)\n",
        "\n",
        "t2 = time()\n",
        "\n",
        "t = (t2 - t1) / 60\n",
        "\n",
        "print('Took {} min'.format(t))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Took 14.381852738062541 min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pILIhW75QSJv",
        "colab_type": "code",
        "outputId": "083cf65b-4724-43ba-d68b-3124023fb29e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "df_train['review_processed'] = X_train\n",
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review_processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I could never remember the name of this show. ...</td>\n",
              "      <td>1</td>\n",
              "      <td>could never remember name show use watch 8 rem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Going into this movie, I had heard good things...</td>\n",
              "      <td>1</td>\n",
              "      <td>going movie heard good things coming really am...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The only scary thing about this movie is the t...</td>\n",
              "      <td>0</td>\n",
              "      <td>scary thing movie thought whoever made might m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This deserves a 12 out of 10. An absolutely re...</td>\n",
              "      <td>1</td>\n",
              "      <td>deserves 12 10 absolutely refreshing show real...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Joan Fontaine is \"A Damsel in Distress\" in thi...</td>\n",
              "      <td>1</td>\n",
              "      <td>joan fontaine damsel distress 1937 musical sta...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  sentiment  \\\n",
              "0  I could never remember the name of this show. ...          1   \n",
              "1  Going into this movie, I had heard good things...          1   \n",
              "2  The only scary thing about this movie is the t...          0   \n",
              "3  This deserves a 12 out of 10. An absolutely re...          1   \n",
              "4  Joan Fontaine is \"A Damsel in Distress\" in thi...          1   \n",
              "\n",
              "                                    review_processed  \n",
              "0  could never remember name show use watch 8 rem...  \n",
              "1  going movie heard good things coming really am...  \n",
              "2  scary thing movie thought whoever made might m...  \n",
              "3  deserves 12 10 absolutely refreshing show real...  \n",
              "4  joan fontaine damsel distress 1937 musical sta...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "metadata": {
        "id": "2XudtfS1g3wT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "save_df(df=df_train, path=path, save_name='df_train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YlCB09DshTs_",
        "colab_type": "code",
        "outputId": "9af9a5af-5395-4895-f2b6-94f7b2daa2c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "t1 = time()\n",
        "\n",
        "df_test['review_processed'] = df_test['review'].apply(preprocess_text)\n",
        "\n",
        "t2 = time()\n",
        "\n",
        "t = (t2 - t1) / 60\n",
        "\n",
        "save_df(df=df_test, path=path, save_name='df_test')\n",
        "\n",
        "print('Took {} min'.format(t))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Took 13.990289672215779 min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uUt3V0gaovvf",
        "colab_type": "code",
        "outputId": "8928eae5-03dd-4de0-89d3-e5546fb250fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "df_test.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review_processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"Thunderbolt\" is probably Jackie Chan's worst ...</td>\n",
              "      <td>0</td>\n",
              "      <td>thunderbolt probably jackie chan worst movie s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This is the worst movie that I have ever seen....</td>\n",
              "      <td>0</td>\n",
              "      <td>worst movie ever seen first thought going good...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(Warning: Some spoilers ahead.)&lt;br /&gt;&lt;br /&gt;Wha...</td>\n",
              "      <td>0</td>\n",
              "      <td>warning spoilers ahead incredibly crappy movie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This film is a perfect example of how to take ...</td>\n",
              "      <td>0</td>\n",
              "      <td>film perfect example take fascinating subject ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ok, everybody agreed on what was the best seas...</td>\n",
              "      <td>1</td>\n",
              "      <td>ok everybody agreed best season first killing ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  sentiment  \\\n",
              "0  \"Thunderbolt\" is probably Jackie Chan's worst ...          0   \n",
              "1  This is the worst movie that I have ever seen....          0   \n",
              "2  (Warning: Some spoilers ahead.)<br /><br />Wha...          0   \n",
              "3  This film is a perfect example of how to take ...          0   \n",
              "4  Ok, everybody agreed on what was the best seas...          1   \n",
              "\n",
              "                                    review_processed  \n",
              "0  thunderbolt probably jackie chan worst movie s...  \n",
              "1  worst movie ever seen first thought going good...  \n",
              "2  warning spoilers ahead incredibly crappy movie...  \n",
              "3  film perfect example take fascinating subject ...  \n",
              "4  ok everybody agreed best season first killing ...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "metadata": {
        "id": "CrBpMg0lZta7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Modeling with CountVectorizer and SVC"
      ]
    },
    {
      "metadata": {
        "id": "9nOUxeDI_3Pw",
        "colab_type": "code",
        "outputId": "15b4a026-91d8-44e7-cc0f-3882ad8385fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# Transform each text into a vector of word counts\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "training_features = vectorizer.fit_transform(df_train['review_processed'])    \n",
        "test_features = vectorizer.transform(df_test['review_processed'])\n",
        "\n",
        "# Training\n",
        "model = LinearSVC()\n",
        "model.fit(training_features, df_train['sentiment'])\n",
        "y_pred = model.predict(test_features)\n",
        "\n",
        "# Evaluation\n",
        "acc = accuracy_score(df_test['sentiment'], y_pred)\n",
        "\n",
        "print(\"Accuracy on test set: {:.2%}\".format(acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test set: 84.14%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ANS68BeHZ6MF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Modeling with Word Embedding and Neural Networks"
      ]
    },
    {
      "metadata": {
        "id": "0MHQgOfOmDYP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the spacy model\n",
        "nlp = spacy.load('en_core_web_md')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ioelJkF1OXQf",
        "colab_type": "code",
        "outputId": "34f35ce0-7cde-4fcb-c743-1e2f0f1ec675",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "t1 = time()\n",
        "\n",
        "X_train = np.array(list(df_train['review_processed'].apply(lambda x: nlp(x).vector.tolist())))\n",
        "\n",
        "t2 = time()\n",
        "\n",
        "t = (t2 - t1) / 60\n",
        "\n",
        "path_name = os.path.join(path, 'X_train_vector.csv')\n",
        "\n",
        "np.savetxt(path_name, X_train, delimiter=',') \n",
        "\n",
        "print('Took {} min'.format(t))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Took 21.16675995985667 min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Xb99GpAdrzxF",
        "colab_type": "code",
        "outputId": "2fa9e056-fb70-4be7-ab98-ef6b5e83d436",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "t1 = time()\n",
        "\n",
        "X_test = np.array(list(df_test['review_processed'].apply(lambda x: nlp(x).vector.tolist())))\n",
        "\n",
        "t2 = time()\n",
        "\n",
        "t = (t2 - t1) / 60\n",
        "\n",
        "path_name = os.path.join(path, 'X_test_vector.csv')\n",
        "\n",
        "np.savetxt(path_name, X_test, delimiter=',') \n",
        "\n",
        "print('Took {} min'.format(t))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Took 20.361665081977844 min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gpZZYlazqqc8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tUS2gMCa4_fA",
        "colab_type": "code",
        "outputId": "9de7f689-6609-463c-f4e1-a29cbd86ab31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Get the first 1000 samples from train dataset\n",
        "#X_train, y_train = X_train[:1000,], y_train[:1000]\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25000, 300), (25000,), (25000, 300), (25000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "euzMlXJB7eWc",
        "colab_type": "code",
        "outputId": "1f29527f-e361-41ed-cd3f-b8d9021fd8f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3468
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.optimizers import RMSprop\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=300, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "rmsprop = RMSprop(lr=0.001)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=rmsprop,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          epochs=100,\n",
        "          batch_size=128)\n",
        "\n",
        "score = model.evaluate(X_test, y_test, batch_size=128)\n",
        "print(\"\\nAccuracy on the test set is: {}\".format(score[1]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "25000/25000 [==============================] - 1s 47us/step - loss: 0.5853 - acc: 0.7140\n",
            "Epoch 2/100\n",
            "25000/25000 [==============================] - 1s 30us/step - loss: 0.4689 - acc: 0.7931\n",
            "Epoch 3/100\n",
            "25000/25000 [==============================] - 1s 31us/step - loss: 0.4266 - acc: 0.8143\n",
            "Epoch 4/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.4032 - acc: 0.8240\n",
            "Epoch 5/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3911 - acc: 0.8314\n",
            "Epoch 6/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3835 - acc: 0.8325\n",
            "Epoch 7/100\n",
            "25000/25000 [==============================] - 1s 31us/step - loss: 0.3790 - acc: 0.8366\n",
            "Epoch 8/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3736 - acc: 0.8410\n",
            "Epoch 9/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3704 - acc: 0.8402\n",
            "Epoch 10/100\n",
            "25000/25000 [==============================] - 1s 31us/step - loss: 0.3668 - acc: 0.8427\n",
            "Epoch 11/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3643 - acc: 0.8424\n",
            "Epoch 12/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3616 - acc: 0.8466\n",
            "Epoch 13/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3604 - acc: 0.8450\n",
            "Epoch 14/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3585 - acc: 0.8494\n",
            "Epoch 15/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3559 - acc: 0.8484\n",
            "Epoch 16/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3554 - acc: 0.8483\n",
            "Epoch 17/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3546 - acc: 0.8495\n",
            "Epoch 18/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3522 - acc: 0.8490\n",
            "Epoch 19/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3507 - acc: 0.8497\n",
            "Epoch 20/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3511 - acc: 0.8518\n",
            "Epoch 21/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3509 - acc: 0.8513\n",
            "Epoch 22/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3499 - acc: 0.8501\n",
            "Epoch 23/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3503 - acc: 0.8529\n",
            "Epoch 24/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3475 - acc: 0.8524\n",
            "Epoch 25/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3455 - acc: 0.8508\n",
            "Epoch 26/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3467 - acc: 0.8553\n",
            "Epoch 27/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3436 - acc: 0.8548\n",
            "Epoch 28/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3457 - acc: 0.8557\n",
            "Epoch 29/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3448 - acc: 0.8550\n",
            "Epoch 30/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3455 - acc: 0.8530\n",
            "Epoch 31/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3421 - acc: 0.8564\n",
            "Epoch 32/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3406 - acc: 0.8550\n",
            "Epoch 33/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3414 - acc: 0.8542\n",
            "Epoch 34/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3409 - acc: 0.8556\n",
            "Epoch 35/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3410 - acc: 0.8563\n",
            "Epoch 36/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3388 - acc: 0.8548\n",
            "Epoch 37/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3394 - acc: 0.8565\n",
            "Epoch 38/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3390 - acc: 0.8577\n",
            "Epoch 39/100\n",
            "25000/25000 [==============================] - 1s 31us/step - loss: 0.3370 - acc: 0.8578\n",
            "Epoch 40/100\n",
            "25000/25000 [==============================] - 1s 31us/step - loss: 0.3393 - acc: 0.8566\n",
            "Epoch 41/100\n",
            "25000/25000 [==============================] - 1s 31us/step - loss: 0.3363 - acc: 0.8586\n",
            "Epoch 42/100\n",
            "25000/25000 [==============================] - 1s 31us/step - loss: 0.3373 - acc: 0.8591\n",
            "Epoch 43/100\n",
            "25000/25000 [==============================] - 1s 31us/step - loss: 0.3389 - acc: 0.8575\n",
            "Epoch 44/100\n",
            "25000/25000 [==============================] - 1s 31us/step - loss: 0.3382 - acc: 0.8567\n",
            "Epoch 45/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3352 - acc: 0.8585\n",
            "Epoch 46/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3349 - acc: 0.8596\n",
            "Epoch 47/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3355 - acc: 0.8574\n",
            "Epoch 48/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3336 - acc: 0.8610\n",
            "Epoch 49/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3325 - acc: 0.8609\n",
            "Epoch 50/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3313 - acc: 0.8602\n",
            "Epoch 51/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3344 - acc: 0.8592\n",
            "Epoch 52/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3311 - acc: 0.8609\n",
            "Epoch 53/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3317 - acc: 0.8608\n",
            "Epoch 54/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3347 - acc: 0.8581\n",
            "Epoch 55/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3307 - acc: 0.8616\n",
            "Epoch 56/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3309 - acc: 0.8615\n",
            "Epoch 57/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3318 - acc: 0.8610\n",
            "Epoch 58/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3323 - acc: 0.8598\n",
            "Epoch 59/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3282 - acc: 0.8617\n",
            "Epoch 60/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3289 - acc: 0.8605\n",
            "Epoch 61/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3286 - acc: 0.8609\n",
            "Epoch 62/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3294 - acc: 0.8611\n",
            "Epoch 63/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3291 - acc: 0.8610\n",
            "Epoch 64/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3314 - acc: 0.8612\n",
            "Epoch 65/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3285 - acc: 0.8616\n",
            "Epoch 66/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3291 - acc: 0.8610\n",
            "Epoch 67/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3258 - acc: 0.8641\n",
            "Epoch 68/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3305 - acc: 0.8635\n",
            "Epoch 69/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3272 - acc: 0.8645\n",
            "Epoch 70/100\n",
            "25000/25000 [==============================] - 1s 31us/step - loss: 0.3274 - acc: 0.8623\n",
            "Epoch 71/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3265 - acc: 0.8656\n",
            "Epoch 72/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3281 - acc: 0.8625\n",
            "Epoch 73/100\n",
            "25000/25000 [==============================] - 1s 31us/step - loss: 0.3238 - acc: 0.8650\n",
            "Epoch 74/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3248 - acc: 0.8637\n",
            "Epoch 75/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3267 - acc: 0.8638\n",
            "Epoch 76/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3250 - acc: 0.8639\n",
            "Epoch 77/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3246 - acc: 0.8640\n",
            "Epoch 78/100\n",
            "25000/25000 [==============================] - 1s 31us/step - loss: 0.3226 - acc: 0.8662\n",
            "Epoch 79/100\n",
            "25000/25000 [==============================] - 1s 31us/step - loss: 0.3257 - acc: 0.8658\n",
            "Epoch 80/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3247 - acc: 0.8630\n",
            "Epoch 81/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3235 - acc: 0.8642\n",
            "Epoch 82/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3243 - acc: 0.8664\n",
            "Epoch 83/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3230 - acc: 0.8642\n",
            "Epoch 84/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3216 - acc: 0.8657\n",
            "Epoch 85/100\n",
            "25000/25000 [==============================] - 1s 31us/step - loss: 0.3251 - acc: 0.8636\n",
            "Epoch 86/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3248 - acc: 0.8635\n",
            "Epoch 87/100\n",
            "25000/25000 [==============================] - 1s 31us/step - loss: 0.3225 - acc: 0.8653\n",
            "Epoch 88/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3206 - acc: 0.8664\n",
            "Epoch 89/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3206 - acc: 0.8674\n",
            "Epoch 90/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3213 - acc: 0.8656\n",
            "Epoch 91/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3225 - acc: 0.8664\n",
            "Epoch 92/100\n",
            "25000/25000 [==============================] - 1s 31us/step - loss: 0.3224 - acc: 0.8649\n",
            "Epoch 93/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3203 - acc: 0.8668\n",
            "Epoch 94/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3200 - acc: 0.8668\n",
            "Epoch 95/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3174 - acc: 0.8666\n",
            "Epoch 96/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3180 - acc: 0.8688\n",
            "Epoch 97/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3176 - acc: 0.8666\n",
            "Epoch 98/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3196 - acc: 0.8664\n",
            "Epoch 99/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3186 - acc: 0.8671\n",
            "Epoch 100/100\n",
            "25000/25000 [==============================] - 1s 34us/step - loss: 0.3184 - acc: 0.8690\n",
            "25000/25000 [==============================] - 0s 19us/step\n",
            "\n",
            "Accuracy on the test set is: 0.845720000038147\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QakhZoqXaEP7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Modeling with Wprd Embedding and RNN"
      ]
    },
    {
      "metadata": {
        "id": "rbPsVBteChfq",
        "colab_type": "code",
        "outputId": "05756683-126b-4c01-df78-96eb0a1568aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1067
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import LSTM\n",
        "\n",
        "#max_features = 1024\n",
        "\n",
        "model = Sequential()\n",
        "#model.add(Embedding(max_features, output_dim=256))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=16, epochs=10)\n",
        "score = model.evaluate(X_test, y_test, batch_size=16)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-d2786389e770>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0;31m# to match the value shapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_set_inputs\u001b[0;34m(self, inputs, outputs, training)\u001b[0m\n\u001b[1;32m    587\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_input_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer lstm_1: expected ndim=3, found ndim=2"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "WzSbsvNxBfxK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## To-Do's\n",
        " \n",
        "- preprocess using spaCy\n",
        "- lemmatize based on pos: https://stackoverflow.com/questions/41824782/lemmatize-string-according-to-pos-nlp"
      ]
    },
    {
      "metadata": {
        "id": "vsOGCxY595k5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cosine_similarity(v1, v2):\n",
        "  return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JGj4dSmSIIFm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Log\n",
        "- original linearSVC: 84.14%\n",
        "- Initial NN: 85.05%\n",
        "- SVC with preprocess: 84.14%\n",
        "- NN with preprocess and new embed: 85.53%\n",
        "\n",
        "\n",
        "took 37.5 min to convert to embedding before preprocessing, 20 min after preprocessing."
      ]
    },
    {
      "metadata": {
        "id": "XQ0KLiwr7Gnq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
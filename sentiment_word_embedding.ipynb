{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_word_embedding.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/georgeliu1998/sentiment_word_embedding/blob/master/sentiment_word_embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "0fnH-78sMTIj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from numpy.random import seed\n",
        "seed(8)\n",
        "\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(8)\n",
        "\n",
        "import numpy as np\n",
        "seed = np.random.RandomState(8)\n",
        "\n",
        "import urllib.request\n",
        "import tarfile\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "from time import time\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d6_GZp-uB6Pg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "5826d428-91db-4ab8-ccaf-11f8d2e8ac32"
      },
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "TebrmRNH7yX_",
        "colab_type": "code",
        "outputId": "4128c043-3b6e-4efc-c1c1-27a3f0f3149e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_md==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.0.0/en_core_web_md-2.0.0.tar.gz#egg=en_core_web_md==2.0.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.0.0/en_core_web_md-2.0.0.tar.gz (120.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 120.9MB 52.3MB/s \n",
            "\u001b[?25hInstalling collected packages: en-core-web-md\n",
            "  Running setup.py install for en-core-web-md ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\n",
            "\u001b[?25hSuccessfully installed en-core-web-md-2.0.0\n",
            "\n",
            "\u001b[93m    Linking successful\u001b[0m\n",
            "    /usr/local/lib/python3.6/dist-packages/en_core_web_md -->\n",
            "    /usr/local/lib/python3.6/dist-packages/spacy/data/en_core_web_md\n",
            "\n",
            "    You can now load the model via spacy.load('en_core_web_md')\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JYC2cCNcik-Q",
        "colab_type": "code",
        "outputId": "7f2fd052-2cdb-40c2-e5eb-a2026aa9ea3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xJJvv-Xaoc0n",
        "colab_type": "code",
        "outputId": "94b731c8-b950-431b-c917-8c2d043427d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "url = 'http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
        "\n",
        "path = './gdrive/My Drive/WorkingDir/sentiment_word_embedding'\n",
        "download_folder = 'raw_data'\n",
        "download_name = 'imdb.tar.gz'\n",
        "path_name = os.path.join(path, download_folder, download_name)\n",
        "\n",
        "# Download data to the specified path\n",
        "urllib.request.urlretrieve(url, path_name)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./gdrive/My Drive/WorkingDir/sentiment_word_embedding/raw_data/imdb.tar.gz',\n",
              " <http.client.HTTPMessage at 0x7fa4dbb55898>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "130d3Cajreqs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#extract_path = os.path.join(path, download_folder)\n",
        "\n",
        "with tarfile.open(path_name) as tar:\n",
        "  #tar.extractall(path=extract_path)\n",
        "  tar.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ci38QxEB_K7x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_imdb(path):\n",
        "  \"\"\"\n",
        "  Loads train and test data into dataframes.\n",
        "\n",
        "  Params\n",
        "  ---------------------\n",
        "  path: str\n",
        "    The path to the unzipped aclImdb folder.\n",
        "\n",
        "  Returns\n",
        "  ---------------------\n",
        "  df_train, df_test: tuple of of pandas df\n",
        "    The dataframes created from data\n",
        "  \"\"\"\n",
        "\n",
        "  data = {}\n",
        "\n",
        "  for split in ['train', 'test']:\n",
        "    data[split] = []\n",
        "\n",
        "    for label in ['pos', 'neg']:\n",
        "      sentiment = 1 if label == 'pos' else 0\n",
        "      file_names = os.listdir(os.path.join(path, split, label))\n",
        "\n",
        "      for file_name in file_names:\n",
        "        file_path = os.path.join(path, split, label, file_name)\n",
        "        with open(file_path, \"r\") as f:\n",
        "          review = f.read()\n",
        "\n",
        "          data[split].append([review, sentiment])\n",
        "\n",
        "  np.random.shuffle(data['train'])        \n",
        "  df_train = pd.DataFrame(data['train'], columns=['review', 'sentiment'])\n",
        "\n",
        "  np.random.shuffle(data['test'])\n",
        "  df_test = pd.DataFrame(data['test'], columns=['review', 'sentiment'])\n",
        "\n",
        "  return df_train, df_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s85H2xtP_Rge",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#data_path = os.path.join(extract_path, 'aclImdb')\n",
        "df_train, df_test = load_imdb('./aclImdb')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "01VwUGX5p4fo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_df(df, path, save_name):\n",
        "  file_name = save_name + '.csv'\n",
        "  path_name = os.path.join(path, file_name)\n",
        "  \n",
        "  df.to_csv(path_name, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0EERavHavVyl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "save_df(df=df_train, path=path, save_name='df_train')\n",
        "save_df(df=df_test, path=path, save_name='df_test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c_dFI3BIrAfA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path = './gdrive/My Drive/WorkingDir/sentiment_word_embedding'\n",
        "\n",
        "df_train = pd.read_csv(os.path.join(path, 'df_train.csv'))\n",
        "df_test = pd.read_csv(os.path.join(path, 'df_test.csv'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K7nVV-rXzqDz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ee907024-b602-4a35-aa0d-cdc7b660a7e6"
      },
      "cell_type": "code",
      "source": [
        "df_train[df_train.review.str.contains('<.*?>')]['review'].iloc[60]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The movie appeals to public due to charisma of Ben Stiller and notoriety of J. Aniston. It seems that we have here a recipe for a successful title, but there\\'s nothing successful in this movie.<br /><br />Polly is very well played by Aniston, no doubt. This is the kind of character which suits her perfectly. <br /><br />Bem Stiller is the same troublesome guy like in \" Meet the parents\", but in this movie the comic scenes are few compared to the title mentioned above.<br /><br />The script is very poor with nothing special at all. With this two well payed actors the things could get a lot better - but what can they do when there is such a poor story and script.<br /><br />4 out of 10.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "X_Z5HPpJVStz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def measure_time(func):\n",
        "  \"\"\"\n",
        "  Tests how long a given function takes to run.\n",
        "  \n",
        "  \"\"\"\n",
        "  t1 = time()\n",
        " \n",
        "  func\n",
        "  \n",
        "  t2 = time()\n",
        "  \n",
        "  t_sec = t2 - t1 \n",
        "  t_min = t_sec / 60\n",
        "\n",
        "  print(\"It took {:.2f} seconds or {:.2f} minutes.\".format(t_sec, t_min))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X5zWJ-deU7ps",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess_text(text, lemmatizing=False):\n",
        "    \"\"\"\n",
        "    Preprocesses text by removing all stop words and lemmatizing.\n",
        "    \n",
        "    Params\n",
        "    --------------\n",
        "    text: str\n",
        "      the string to be cleaned\n",
        "    \n",
        "    Returns\n",
        "    --------------\n",
        "    text: str\n",
        "      the cleaned string\n",
        "\n",
        "    \"\"\"\n",
        "    text = text.lower()\n",
        "    \n",
        "    if lemmatizing:\n",
        "      lemmatizer = WordNetLemmatizer()\n",
        "      text = ' '.join([lemmatizer.lemmatize(word, pos='v') for word in text.split()])\n",
        "    \n",
        "    # Remove html tags\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    \n",
        "    # Replace punctuation with spaces\n",
        "    translator = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
        "    text = text.translate(translator)\n",
        "\n",
        "    # Remove stop words\n",
        "    text = ' '.join([word for word in text.split() if word not in stopwords.words('english')])\n",
        "    \n",
        "    # Remove additional white spaces\n",
        "    text = ' '.join(text.split())\n",
        "    \n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ok0pLI_fPqDY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ac534af-f104-4ce2-a7c0-17e3441d83e4"
      },
      "cell_type": "code",
      "source": [
        "t1 = time()\n",
        "\n",
        "X_train = df_train['review'].apply(preprocess_text)\n",
        "\n",
        "t2 = time()\n",
        "\n",
        "t = (t2 - t1) / 60\n",
        "\n",
        "print('Took {} min'.format(t))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Took 14.381852738062541 min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pILIhW75QSJv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "083cf65b-4724-43ba-d68b-3124023fb29e"
      },
      "cell_type": "code",
      "source": [
        "df_train['review_processed'] = X_train\n",
        "df_train.head()"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review_processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I could never remember the name of this show. ...</td>\n",
              "      <td>1</td>\n",
              "      <td>could never remember name show use watch 8 rem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Going into this movie, I had heard good things...</td>\n",
              "      <td>1</td>\n",
              "      <td>going movie heard good things coming really am...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The only scary thing about this movie is the t...</td>\n",
              "      <td>0</td>\n",
              "      <td>scary thing movie thought whoever made might m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This deserves a 12 out of 10. An absolutely re...</td>\n",
              "      <td>1</td>\n",
              "      <td>deserves 12 10 absolutely refreshing show real...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Joan Fontaine is \"A Damsel in Distress\" in thi...</td>\n",
              "      <td>1</td>\n",
              "      <td>joan fontaine damsel distress 1937 musical sta...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  sentiment  \\\n",
              "0  I could never remember the name of this show. ...          1   \n",
              "1  Going into this movie, I had heard good things...          1   \n",
              "2  The only scary thing about this movie is the t...          0   \n",
              "3  This deserves a 12 out of 10. An absolutely re...          1   \n",
              "4  Joan Fontaine is \"A Damsel in Distress\" in thi...          1   \n",
              "\n",
              "                                    review_processed  \n",
              "0  could never remember name show use watch 8 rem...  \n",
              "1  going movie heard good things coming really am...  \n",
              "2  scary thing movie thought whoever made might m...  \n",
              "3  deserves 12 10 absolutely refreshing show real...  \n",
              "4  joan fontaine damsel distress 1937 musical sta...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "metadata": {
        "id": "2XudtfS1g3wT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "save_df(df=df_train, path=path, save_name='df_train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YlCB09DshTs_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9af9a5af-5395-4895-f2b6-94f7b2daa2c5"
      },
      "cell_type": "code",
      "source": [
        "t1 = time()\n",
        "\n",
        "df_test['review_processed'] = df_test['review'].apply(preprocess_text)\n",
        "\n",
        "t2 = time()\n",
        "\n",
        "t = (t2 - t1) / 60\n",
        "\n",
        "save_df(df=df_test, path=path, save_name='df_test')\n",
        "\n",
        "print('Took {} min'.format(t))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Took 13.990289672215779 min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uUt3V0gaovvf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8928eae5-03dd-4de0-89d3-e5546fb250fa"
      },
      "cell_type": "code",
      "source": [
        "df_test.head()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review_processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"Thunderbolt\" is probably Jackie Chan's worst ...</td>\n",
              "      <td>0</td>\n",
              "      <td>thunderbolt probably jackie chan worst movie s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This is the worst movie that I have ever seen....</td>\n",
              "      <td>0</td>\n",
              "      <td>worst movie ever seen first thought going good...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(Warning: Some spoilers ahead.)&lt;br /&gt;&lt;br /&gt;Wha...</td>\n",
              "      <td>0</td>\n",
              "      <td>warning spoilers ahead incredibly crappy movie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>This film is a perfect example of how to take ...</td>\n",
              "      <td>0</td>\n",
              "      <td>film perfect example take fascinating subject ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ok, everybody agreed on what was the best seas...</td>\n",
              "      <td>1</td>\n",
              "      <td>ok everybody agreed best season first killing ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  sentiment  \\\n",
              "0  \"Thunderbolt\" is probably Jackie Chan's worst ...          0   \n",
              "1  This is the worst movie that I have ever seen....          0   \n",
              "2  (Warning: Some spoilers ahead.)<br /><br />Wha...          0   \n",
              "3  This film is a perfect example of how to take ...          0   \n",
              "4  Ok, everybody agreed on what was the best seas...          1   \n",
              "\n",
              "                                    review_processed  \n",
              "0  thunderbolt probably jackie chan worst movie s...  \n",
              "1  worst movie ever seen first thought going good...  \n",
              "2  warning spoilers ahead incredibly crappy movie...  \n",
              "3  film perfect example take fascinating subject ...  \n",
              "4  ok everybody agreed best season first killing ...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "metadata": {
        "id": "9nOUxeDI_3Pw",
        "colab_type": "code",
        "outputId": "15b4a026-91d8-44e7-cc0f-3882ad8385fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# Transform each text into a vector of word counts\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "training_features = vectorizer.fit_transform(df_train['review_processed'])    \n",
        "test_features = vectorizer.transform(df_test['review_processed'])\n",
        "\n",
        "# Training\n",
        "model = LinearSVC()\n",
        "model.fit(training_features, df_train['sentiment'])\n",
        "y_pred = model.predict(test_features)\n",
        "\n",
        "# Evaluation\n",
        "acc = accuracy_score(df_test['sentiment'], y_pred)\n",
        "\n",
        "print(\"Accuracy on test set: {:.2%}\".format(acc))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on test set: 84.14%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "0MHQgOfOmDYP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the spacy model that you have installed\n",
        "nlp = spacy.load('en_core_web_md')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ioelJkF1OXQf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = np.array(list(train['text'].str.lower().apply(lambda x: nlp(x).vector.tolist())))\n",
        "np.savetxt(\"./gdrive/My Drive/WorkingDir/sentiment_word_embedding/X_train.csv\", X_train, delimiter=\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zk_Dy_g14kxA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.savetxt(\"./gdrive/My Drive/WorkingDir/sentiment_word_embedding/y_train.csv\", y_train, delimiter=\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gpZZYlazqqc8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train = np.loadtxt(\"./gdrive/My Drive/WorkingDir/sentiment_word_embedding/X_train.csv\", delimiter=\",\")\n",
        "y_train = np.loadtxt(\"./gdrive/My Drive/WorkingDir/sentiment_word_embedding/y_train.csv\", delimiter=\",\")\n",
        "X_test = np.loadtxt(\"./gdrive/My Drive/WorkingDir/sentiment_word_embedding/X_test.csv\", delimiter=\",\")\n",
        "y_test = np.loadtxt(\"./gdrive/My Drive/WorkingDir/sentiment_word_embedding/y_test.csv\", delimiter=\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tUS2gMCa4_fA",
        "colab_type": "code",
        "outputId": "b8ebb35a-a43d-482a-f373-293cffe4a3b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Get the first 1000 samples from train dataset\n",
        "#X_train, y_train = X_train[:1000,], y_train[:1000]\n",
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25000, 300), (25000,), (25000, 300), (25000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "metadata": {
        "id": "euzMlXJB7eWc",
        "colab_type": "code",
        "outputId": "86bab1ab-148e-46af-b0ed-ef51cf51db77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3451
        }
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=300, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          epochs=100,\n",
        "          batch_size=128)\n",
        "\n",
        "score = model.evaluate(X_test, y_test, batch_size=128)\n",
        "print(\"Accuracy on the test set is: {}\".format(score[1]))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "25000/25000 [==============================] - 1s 42us/step - loss: 0.5857 - acc: 0.7167\n",
            "Epoch 2/100\n",
            "25000/25000 [==============================] - 1s 29us/step - loss: 0.4721 - acc: 0.7886\n",
            "Epoch 3/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.4276 - acc: 0.8115\n",
            "Epoch 4/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.4074 - acc: 0.8229\n",
            "Epoch 5/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3937 - acc: 0.8285\n",
            "Epoch 6/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3855 - acc: 0.8342\n",
            "Epoch 7/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3802 - acc: 0.8358\n",
            "Epoch 8/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3749 - acc: 0.8395\n",
            "Epoch 9/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3720 - acc: 0.8401\n",
            "Epoch 10/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3675 - acc: 0.8433\n",
            "Epoch 11/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3653 - acc: 0.8457\n",
            "Epoch 12/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3634 - acc: 0.8464\n",
            "Epoch 13/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3588 - acc: 0.8466\n",
            "Epoch 14/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3590 - acc: 0.8480\n",
            "Epoch 15/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3588 - acc: 0.8476\n",
            "Epoch 16/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3569 - acc: 0.8487\n",
            "Epoch 17/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3542 - acc: 0.8472\n",
            "Epoch 18/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3557 - acc: 0.8485\n",
            "Epoch 19/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3523 - acc: 0.8502\n",
            "Epoch 20/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3510 - acc: 0.8511\n",
            "Epoch 21/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3525 - acc: 0.8484\n",
            "Epoch 22/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3516 - acc: 0.8502\n",
            "Epoch 23/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3499 - acc: 0.8511\n",
            "Epoch 24/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3479 - acc: 0.8544\n",
            "Epoch 25/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3465 - acc: 0.8514\n",
            "Epoch 26/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3472 - acc: 0.8540\n",
            "Epoch 27/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3463 - acc: 0.8523\n",
            "Epoch 28/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3449 - acc: 0.8535\n",
            "Epoch 29/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3415 - acc: 0.8554\n",
            "Epoch 30/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3449 - acc: 0.8542\n",
            "Epoch 31/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3431 - acc: 0.8539\n",
            "Epoch 32/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3430 - acc: 0.8553\n",
            "Epoch 33/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3433 - acc: 0.8546\n",
            "Epoch 34/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3428 - acc: 0.8552\n",
            "Epoch 35/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3415 - acc: 0.8556\n",
            "Epoch 36/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3390 - acc: 0.8544\n",
            "Epoch 37/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3410 - acc: 0.8561\n",
            "Epoch 38/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3398 - acc: 0.8562\n",
            "Epoch 39/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3396 - acc: 0.8556\n",
            "Epoch 40/100\n",
            "25000/25000 [==============================] - 1s 34us/step - loss: 0.3365 - acc: 0.8594\n",
            "Epoch 41/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3413 - acc: 0.8569\n",
            "Epoch 42/100\n",
            "25000/25000 [==============================] - 1s 34us/step - loss: 0.3398 - acc: 0.8567\n",
            "Epoch 43/100\n",
            "25000/25000 [==============================] - 1s 34us/step - loss: 0.3382 - acc: 0.8569\n",
            "Epoch 44/100\n",
            "25000/25000 [==============================] - 1s 34us/step - loss: 0.3371 - acc: 0.8577\n",
            "Epoch 45/100\n",
            "25000/25000 [==============================] - 1s 35us/step - loss: 0.3371 - acc: 0.8579\n",
            "Epoch 46/100\n",
            "25000/25000 [==============================] - 1s 35us/step - loss: 0.3344 - acc: 0.8600\n",
            "Epoch 47/100\n",
            "25000/25000 [==============================] - 1s 34us/step - loss: 0.3348 - acc: 0.8563\n",
            "Epoch 48/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3361 - acc: 0.8565\n",
            "Epoch 49/100\n",
            "25000/25000 [==============================] - 1s 35us/step - loss: 0.3339 - acc: 0.8612\n",
            "Epoch 50/100\n",
            "25000/25000 [==============================] - 1s 35us/step - loss: 0.3330 - acc: 0.8607\n",
            "Epoch 51/100\n",
            "25000/25000 [==============================] - 1s 35us/step - loss: 0.3356 - acc: 0.8607\n",
            "Epoch 52/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3347 - acc: 0.8592\n",
            "Epoch 53/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3341 - acc: 0.8605\n",
            "Epoch 54/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3332 - acc: 0.8600\n",
            "Epoch 55/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3324 - acc: 0.8594\n",
            "Epoch 56/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3326 - acc: 0.8602\n",
            "Epoch 57/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3330 - acc: 0.8595\n",
            "Epoch 58/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3332 - acc: 0.8602\n",
            "Epoch 59/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3316 - acc: 0.8599\n",
            "Epoch 60/100\n",
            "25000/25000 [==============================] - 1s 34us/step - loss: 0.3308 - acc: 0.8625\n",
            "Epoch 61/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3321 - acc: 0.8612\n",
            "Epoch 62/100\n",
            "25000/25000 [==============================] - 1s 34us/step - loss: 0.3297 - acc: 0.8630\n",
            "Epoch 63/100\n",
            "25000/25000 [==============================] - 1s 35us/step - loss: 0.3309 - acc: 0.8629\n",
            "Epoch 64/100\n",
            "25000/25000 [==============================] - 1s 34us/step - loss: 0.3297 - acc: 0.8616\n",
            "Epoch 65/100\n",
            "25000/25000 [==============================] - 1s 34us/step - loss: 0.3294 - acc: 0.8610\n",
            "Epoch 66/100\n",
            "25000/25000 [==============================] - 1s 35us/step - loss: 0.3305 - acc: 0.8607\n",
            "Epoch 67/100\n",
            "25000/25000 [==============================] - 1s 35us/step - loss: 0.3306 - acc: 0.8629\n",
            "Epoch 68/100\n",
            "25000/25000 [==============================] - 1s 34us/step - loss: 0.3326 - acc: 0.8614\n",
            "Epoch 69/100\n",
            "25000/25000 [==============================] - 1s 34us/step - loss: 0.3277 - acc: 0.8637\n",
            "Epoch 70/100\n",
            "25000/25000 [==============================] - 1s 35us/step - loss: 0.3298 - acc: 0.8616\n",
            "Epoch 71/100\n",
            "25000/25000 [==============================] - 1s 35us/step - loss: 0.3279 - acc: 0.8626\n",
            "Epoch 72/100\n",
            "25000/25000 [==============================] - 1s 35us/step - loss: 0.3287 - acc: 0.8614\n",
            "Epoch 73/100\n",
            "25000/25000 [==============================] - 1s 34us/step - loss: 0.3261 - acc: 0.8628\n",
            "Epoch 74/100\n",
            "25000/25000 [==============================] - 1s 35us/step - loss: 0.3279 - acc: 0.8642\n",
            "Epoch 75/100\n",
            "25000/25000 [==============================] - 1s 34us/step - loss: 0.3306 - acc: 0.8625\n",
            "Epoch 76/100\n",
            "25000/25000 [==============================] - 1s 35us/step - loss: 0.3269 - acc: 0.8641\n",
            "Epoch 77/100\n",
            "25000/25000 [==============================] - 1s 34us/step - loss: 0.3242 - acc: 0.8648\n",
            "Epoch 78/100\n",
            "25000/25000 [==============================] - 1s 34us/step - loss: 0.3271 - acc: 0.8633\n",
            "Epoch 79/100\n",
            "25000/25000 [==============================] - 1s 34us/step - loss: 0.3263 - acc: 0.8642\n",
            "Epoch 80/100\n",
            "25000/25000 [==============================] - 1s 34us/step - loss: 0.3255 - acc: 0.8636\n",
            "Epoch 81/100\n",
            "25000/25000 [==============================] - 1s 34us/step - loss: 0.3261 - acc: 0.8631\n",
            "Epoch 82/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3241 - acc: 0.8645\n",
            "Epoch 83/100\n",
            "25000/25000 [==============================] - 1s 34us/step - loss: 0.3263 - acc: 0.8634\n",
            "Epoch 84/100\n",
            "25000/25000 [==============================] - 1s 35us/step - loss: 0.3251 - acc: 0.8651\n",
            "Epoch 85/100\n",
            "25000/25000 [==============================] - 1s 34us/step - loss: 0.3236 - acc: 0.8663\n",
            "Epoch 86/100\n",
            "25000/25000 [==============================] - 1s 35us/step - loss: 0.3231 - acc: 0.8649\n",
            "Epoch 87/100\n",
            "25000/25000 [==============================] - 1s 34us/step - loss: 0.3251 - acc: 0.8642\n",
            "Epoch 88/100\n",
            "25000/25000 [==============================] - 1s 34us/step - loss: 0.3236 - acc: 0.8669\n",
            "Epoch 89/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3225 - acc: 0.8649\n",
            "Epoch 90/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3247 - acc: 0.8642\n",
            "Epoch 91/100\n",
            "25000/25000 [==============================] - 1s 34us/step - loss: 0.3231 - acc: 0.8657\n",
            "Epoch 92/100\n",
            "25000/25000 [==============================] - 1s 34us/step - loss: 0.3244 - acc: 0.8665\n",
            "Epoch 93/100\n",
            "25000/25000 [==============================] - 1s 34us/step - loss: 0.3214 - acc: 0.8658\n",
            "Epoch 94/100\n",
            "25000/25000 [==============================] - 1s 32us/step - loss: 0.3224 - acc: 0.8648\n",
            "Epoch 95/100\n",
            "25000/25000 [==============================] - 1s 33us/step - loss: 0.3217 - acc: 0.8647\n",
            "Epoch 96/100\n",
            "25000/25000 [==============================] - 1s 34us/step - loss: 0.3213 - acc: 0.8672\n",
            "Epoch 97/100\n",
            "25000/25000 [==============================] - 1s 34us/step - loss: 0.3225 - acc: 0.8666\n",
            "Epoch 98/100\n",
            "25000/25000 [==============================] - 1s 34us/step - loss: 0.3218 - acc: 0.8674\n",
            "Epoch 99/100\n",
            "25000/25000 [==============================] - 1s 34us/step - loss: 0.3228 - acc: 0.8672\n",
            "Epoch 100/100\n",
            "25000/25000 [==============================] - 1s 34us/step - loss: 0.3219 - acc: 0.8663\n",
            "25000/25000 [==============================] - 0s 17us/step\n",
            "Accuracy on the test set is: 0.8505200000190735\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lqOfQz-WgEk7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def convert_to_embedding(col):\n",
        "  \"\"\"\n",
        "  Converts a pandas column into a numpy array by concatenating average embedding\n",
        "  vectors for all rows in the column\n",
        "  \"\"\"\n",
        "\n",
        "  return np.array(list(col.str.lower().apply(lambda x: nlp(x).vector.tolist())))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M3kDExyuhU9_",
        "colab_type": "code",
        "outputId": "2c1999ee-d5ee-4a1e-f5e0-88664904b8e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "col = test['text']\n",
        "\n",
        "t1 = time()\n",
        "X_test = convert_to_embedding(col)\n",
        "t2 = time()\n",
        "\n",
        "t = t2 - t1\n",
        "\n",
        "t /= 60\n",
        "\n",
        "print(\"Finished cross-valiation. Took {:.1f} min.\".format(t))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished cross-valiation. Took 37.5 min.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C_m_1kBuPHEf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.savetxt(\"./gdrive/My Drive/WorkingDir/sentiment_word_embedding/X_test.csv\", X_test, delimiter=\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J217ter9n3GI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_test = test['sentiment'].values\n",
        "np.savetxt(\"./gdrive/My Drive/WorkingDir/sentiment_word_embedding/y_test.csv\", y_test, delimiter=\",\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CARhfxSxoXMO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e5SBP0-6zpF6",
        "colab_type": "code",
        "outputId": "f14e615b-1be9-4d1f-bd89-28309194dd10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#X_test, y_test = X_test[:1000,], y_test[:1000]\n",
        "X_test.shape, y_test.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1000, 300), (1000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "WzSbsvNxBfxK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## To-Do's\n",
        " \n",
        "- preprocess using spaCy\n",
        "- lemmatize based on pos: https://stackoverflow.com/questions/41824782/lemmatize-string-according-to-pos-nlp"
      ]
    },
    {
      "metadata": {
        "id": "vsOGCxY595k5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cosine_similarity(v1, v2):\n",
        "  return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rbPsVBteChfq",
        "colab_type": "code",
        "outputId": "78700ed6-a77c-4033-ef76-5eb57d237bc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.layers import Input,Dense\n",
        "from keras.models import Model\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        " \n",
        "(data,labels),(x_test,y_test) = mnist.load_data()\n",
        " \n",
        "x_train = data.reshape(len(data),-1)\n",
        "y_train = np_utils.to_categorical(labels, 10)\n",
        " \n",
        "# This returns a tensor\n",
        "inputs = Input(shape=(784,))\n",
        " \n",
        "# a layer instance is callable on a tensor, and returns a tensor\n",
        "x = Dense(64, activation='relu')(inputs)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "predictions = Dense(10, activation='softmax')(x)\n",
        " \n",
        "# This creates a model that includes the Input layer and three Dense layers\n",
        "model = Model(inputs=inputs, outputs=predictions)\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(x_train, y_train)  # starts training"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "Epoch 1/1\n",
            "60000/60000 [==============================] - 19s 313us/step - loss: 6.1711 - acc: 0.6105\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f79545c0b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "vkFs88wpCjYm",
        "colab_type": "code",
        "outputId": "d2f1ac5c-2f52-4930-82ad-fa8896379e6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "data.shape, labels.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "pucHtoj9Cuum",
        "colab_type": "code",
        "outputId": "ca465e04-68d7-488c-fc1d-b30e4b3436af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "x_train.shape, y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (60000, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "JGj4dSmSIIFm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}